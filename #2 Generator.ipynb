{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107b03db-f08e-4d72-a022-68d11fd7a058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 4, 9, 16]\n"
     ]
    }
   ],
   "source": [
    "# DAY 1 - GENERATOR PIPELINES: STREAMLINE OR DIE\n",
    "# CONCEPTS\n",
    "# %%\n",
    "lists = [1,2,3,4]\n",
    "\n",
    "def squared(lists):\n",
    "    l2 = []\n",
    "    for ele in lists:\n",
    "        l2.append(ele*ele)\n",
    "    return l2\n",
    "\n",
    "lists2 = squared(lists)\n",
    "print(lists2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99ae349-e465-4e9d-96be-99a1a87e010e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object gen_sq at 0x000002A54169EE90>\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "def gen_sq(lists):\n",
    "    for ele in lists:\n",
    "        yield ele**2\n",
    "\n",
    "lists_gen = gen_sq(lists)\n",
    "print(lists_gen)\n",
    "print(next(lists_gen))\n",
    "# generators don't hold the result in memory, instead it yields one result at a time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fafbc34-a28a-4df0-804d-4c7422a28920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 4, 9, 16]\n",
      "<generator object <genexpr> at 0x000002A54169F780>\n",
      "[1, 4, 9, 16]\n"
     ]
    }
   ],
   "source": [
    "print([ele**2 for ele in lists])\n",
    "print((ele**2 for ele in lists))\n",
    "print(list((ele**2 for ele in lists)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8573d257-b393-48b6-b39f-dceeead95757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List size: 85176 bytes\n",
      "Generator size: 192 bytes\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "# List comprehension\n",
    "list_comp = [x for x in range(10000)]\n",
    "print(f\"List size: {sys.getsizeof(list_comp)} bytes\")\n",
    "\n",
    "# Generator expression\n",
    "gen_exp = (x for x in range(10000))\n",
    "print(f\"Generator size: {sys.getsizeof(gen_exp)} bytes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0bde3f-a60e-45bd-aaf9-3121740ace8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "afasdjalslfsajaflsjasdljadslsadljsdlaasdsfsadfssafsad\n",
      "bbafasdjalslfsajaflsjasdljadslsadljsdlaasdsfsadfssafsad\n"
     ]
    }
   ],
   "source": [
    "def read_large_file(file_path):\n",
    "    \"\"\"Generator that reads a file line by line\"\"\"\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            yield line.strip()\n",
    "\n",
    "def filter_long_lines(lines, min_length=50):\n",
    "    \"\"\"Generator that filters lines by length\"\"\"\n",
    "    for line in lines:\n",
    "        if len(line) >= min_length:\n",
    "            yield line\n",
    "\n",
    "# Chaining generators - no intermediate lists created\n",
    "long_lines = filter_long_lines(read_large_file('large_file.txt'))\n",
    "print(next(long_lines))\n",
    "print(next(long_lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c34677-6b66-4efc-88a9-82887f3193fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting iteration...\n",
      "Filter function called\n",
      "Reading line 1\n",
      "Processing: line 1\n",
      "Yielding: line 1\n",
      "Got result: line 1\n",
      "Reading line 2\n",
      "Processing: line 2\n",
      "Yielding: line 2\n",
      "Got result: line 2\n",
      "Reading line 3\n",
      "Processing: line 3\n",
      "Yielding: line 3\n",
      "Got result: line 3\n",
      "Starting manual iteration...\n",
      "Manual Filter function called\n",
      "Reading line 1\n",
      "Processing: line 1\n",
      "Yielding: line 1\n",
      "Got result: line 1\n",
      "Reading line 2\n",
      "Processing: line 2\n",
      "Yielding: line 2\n",
      "Got result: line 2\n",
      "Reading line 3\n",
      "Processing: line 3\n",
      "Yielding: line 3\n",
      "Got result: line 3\n"
     ]
    }
   ],
   "source": [
    "def read_large_file(file_path):\n",
    "    print(\"Reading line 1\")\n",
    "    yield \"line 1\"\n",
    "    print(\"Reading line 2\") \n",
    "    yield \"line 2\"\n",
    "    print(\"Reading line 3\")\n",
    "    yield \"line 3\"\n",
    "\n",
    "def filter_long_lines(lines, min_length=2):\n",
    "    print(\"Filter function called\")\n",
    "    for line in lines:  # This works because 'lines' is iterable\n",
    "        print(f\"Processing: {line}\")\n",
    "        if len(line) >= min_length:\n",
    "            print(f\"Yielding: {line}\")\n",
    "            yield line\n",
    "\n",
    "def manual_read_large_file(file_path):\n",
    "    print(\"Reading line 1\")\n",
    "    yield \"line 1\"\n",
    "    print(\"Reading line 2\") \n",
    "    yield \"line 2\"\n",
    "    print(\"Reading line 3\")\n",
    "    yield \"line 3\"\n",
    "\n",
    "def bts_filter_long_lines(lines, min_length=2):\n",
    "    # python hidden implementation\n",
    "    print(\"Manual Filter function called\")\n",
    "    iterator = iter(lines)\n",
    "    while True:\n",
    "        try:\n",
    "            line = next(iterator)\n",
    "            print(f\"Processing: {line}\")\n",
    "            if len(line) >= min_length:\n",
    "                print(f\"Yielding: {line}\")\n",
    "                yield line\n",
    "        except StopIteration:\n",
    "            break\n",
    "\n",
    "# Demo\n",
    "file_gen = read_large_file(\"dummy.txt\")\n",
    "manual_file_gen = manual_read_large_file(\"dummy.txt\")\n",
    "\n",
    "filtered_gen = filter_long_lines(file_gen, min_length=6)\n",
    "\n",
    "manual_filtered_gen = bts_filter_long_lines(manual_file_gen, min_length=6)\n",
    "\n",
    "print(\"Starting iteration...\")\n",
    "for result in filtered_gen:\n",
    "    print(f\"Got result: {result}\")\n",
    "\n",
    "print(\"Starting manual iteration...\")\n",
    "for result in manual_filtered_gen:\n",
    "    print(f\"Got result: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b96a0a7-44cf-412b-af93-eba2dca6a606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'index': 0, 'timestamp': '2025', 'level': '08', 'message': '03 10:00:05,567 '}\n",
      "{'index': 1, 'timestamp': '2025', 'level': '08', 'message': '03 10:00:03,789 '}\n",
      "{'index': 2, 'timestamp': '2025', 'level': '08', 'message': '03 10:00:05,567 '}\n",
      "{'index': 3, 'timestamp': '2025', 'level': '08', 'message': '03 10:00:05,567 '}\n",
      "{'index': 4, 'timestamp': '2025', 'level': '08', 'message': '03 10:00:05,567 '}\n",
      "{'index': 5, 'timestamp': '2025', 'level': '08', 'message': '03 10:00:03,789 '}\n",
      "{'index': 6, 'timestamp': '2025', 'level': '08', 'message': '03 10:00:05,567 '}\n",
      "{'index': 7, 'timestamp': '2025', 'level': '08', 'message': '03 10:00:03,789 '}\n",
      "{'index': 8, 'timestamp': '2025', 'level': '08', 'message': '03 10:00:03,789 '}\n",
      "{'index': 9, 'timestamp': '2025', 'level': '08', 'message': '03 10:00:03,789 '}\n"
     ]
    }
   ],
   "source": [
    "# 3 stage pipeline \n",
    "# read_lines(file_path) → filter_errors(lines) → parse_log(lines)\n",
    "import os\n",
    "\n",
    "file_path = 'large_generator.log'\n",
    "\n",
    "absolute_path = os.path.join(file_path)\n",
    "\n",
    "def read_lines(absolute_path):\n",
    "    try:\n",
    "        with open(absolute_path, mode='r') as file:\n",
    "            for line in file:\n",
    "                yield line\n",
    "    except FileNotFoundError:\n",
    "        print(f'File Not Found: {absolute_path}')\n",
    "        return\n",
    "\n",
    "def filter_errors(lines):\n",
    "    yield from (line for line in lines if line.find('ERROR')+1)\n",
    "\n",
    "def parse_log(lines):\n",
    "    for index, line in enumerate(lines):\n",
    "        yield {\n",
    "            'index': index,\n",
    "            'timestamp': line.split('-')[0],\n",
    "            'level': line.split('-')[1],\n",
    "            'message': line.split('-')[2]\n",
    "        }\n",
    "\n",
    "res = parse_log(filter_errors(read_lines(absolute_path)))\n",
    "\n",
    "for i in range(10):\n",
    "    print(next(res))\n",
    "\n",
    "\n",
    "# print(next(filter_errors(read_lines(absolute_path))))\n",
    "# print(next(filter_errors(read_lines(absolute_path))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c796f4-8f00-4baf-a6f2-b697c6b518d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q. How does generator chaining improve memory use?\n",
    "# A. Generator has lazy evaluation meaning they don't execute the program untill invoked with next(), so they create any value objects even though it will execute functions, and it gives back values one by one on-demand.\n",
    "\n",
    "# Q. What breaks if yield is replaced with return?\n",
    "# A. When we replace yield with return, it will return just the first element of the iterable.\n",
    "\n",
    "# Q. Where can you plug such a pipeline in real ETL jobs?\n",
    "# A. In strea, processing of large files "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
